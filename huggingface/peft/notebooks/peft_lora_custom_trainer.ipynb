{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter-Efficient Finetuning (PEFT) with Low-Level Adaptation (LORA) using HuggingFace PEFT on a single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r ./../requirements.txt\n",
    "%pip install -q --force-reinstall numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "# '2.5.1'\n",
    "# '1.26.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input constants\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HF_PRETRAINED_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "HF_DATASET_COLLECTION = \"glue\"\n",
    "HF_DATASET_CONFIG_NAME = \"mrpc\"  # Microsoft Research Paraphrase Corpus\n",
    "\n",
    "TRAINING_EPOCHS = int(os.getenv('TRAINING_EPOCHS'))\n",
    "TRAINING_BATCH_SIZE = int(os.getenv('TRAINING_BATCH_SIZE'))\n",
    "TRAINING_LEARNING_RATE = float(os.getenv('TRAINING_LEARNING_RATE'))\n",
    "TRAINING_DEVICE = 'gpu' # one of ['cpu', 'gpu', 'mps']\n",
    "\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"attention.q_lin\", \n",
    "    \"attention.k_lin\", \n",
    "    \"attention.v_lin\", \n",
    "    \"attention.out_lin\"\n",
    "]\n",
    "LORA_R = int(os.getenv('LORA_R'))\n",
    "LORA_ALPHA = int(os.getenv('LORA_ALPHA'))\n",
    "LORA_DROPOUT = float(os.getenv('LORA_DROPOUT'))\n",
    "\n",
    "OUTPUT_DIRECTORY = os.path.join('trained', HF_PRETRAINED_MODEL_NAME)\n",
    "HUGGINGFACE_REPO_ID = os.getenv('HUGGINGFACE_REPO_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"HF pretrained model name: {HF_PRETRAINED_MODEL_NAME}\")\n",
    "print(f\"HF datasets name: {HF_DATASET_COLLECTION}\")\n",
    "print(f\"HF task name: {HF_DATASET_CONFIG_NAME}\")\n",
    "\n",
    "print(f\"epochs: {TRAINING_EPOCHS}\")\n",
    "print(f\"batch_size: {TRAINING_BATCH_SIZE}\")\n",
    "print(f\"learning rate (lr): {TRAINING_LEARNING_RATE}\")\n",
    "\n",
    "print(f\"LORA r: {LORA_R}\")\n",
    "print(f\"LORA alpha: {LORA_ALPHA}\")\n",
    "print(f\"LORA droupout: {LORA_DROPOUT}\")\n",
    "\n",
    "print(f\"Using {TRAINING_DEVICE} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets: train, validation, test\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(HF_DATASET_COLLECTION, HF_DATASET_CONFIG_NAME, trust_remote_code=True)  # doctest: +IGNORE_RESULT\n",
    "\n",
    "# /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "#   from .autonotebook import tqdm as notebook_tqdm\n",
    "# Downloading readme: 100%|██████████| 35.3k/35.3k [00:00<00:00, 51.0MB/s]\n",
    "# Downloading data: 100%|██████████| 649k/649k [00:00<00:00, 1.47MB/s]\n",
    "# Downloading data: 100%|██████████| 75.7k/75.7k [00:00<00:00, 249kB/s]\n",
    "# Downloading data: 100%|██████████| 308k/308k [00:00<00:00, 1.02MB/s]\n",
    "# Generating train split: 100%|██████████| 3668/3668 [00:00<00:00, 16329.64 examples/s]\n",
    "# Generating validation split: 100%|██████████| 408/408 [00:00<00:00, 216370.72 examples/s]\n",
    "# Generating test split: 100%|██████████| 1725/1725 [00:00<00:00, 560605.49 examples/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(f\"dataset: {[k for k in dataset]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tokenizer\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(HF_PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "base_model = DistilBertForSequenceClassification.from_pretrained(HF_PRETRAINED_MODEL_NAME)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model.to(device)\n",
    "\n",
    "# Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
    "# You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "# DistilBertForSequenceClassification(\n",
    "#   (distilbert): DistilBertModel(\n",
    "#     (embeddings): Embeddings(\n",
    "#       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "#       (position_embeddings): Embedding(512, 768)\n",
    "#       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "#       (dropout): Dropout(p=0.1, inplace=False)\n",
    "#     )\n",
    "#     (transformer): Transformer(\n",
    "#       (layer): ModuleList(\n",
    "#         (0-5): 6 x TransformerBlock(\n",
    "#           (attention): MultiHeadSelfAttention(\n",
    "#             (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#           )\n",
    "#           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "#           (ffn): FFN(\n",
    "#             (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
    "#             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
    "#             (activation): GELUActivation()\n",
    "#           )\n",
    "#           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "#         )\n",
    "#       )\n",
    "#     )\n",
    "#   )\n",
    "#   (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
    "#   (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
    "#   (dropout): Dropout(p=0.2, inplace=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the dataset\n",
    "# Hugging Face Transformers models expect tokenized input, \n",
    "# rather than the text in the downloaded data.\n",
    "def tokenize_dataset(examples):\n",
    "    return tokenizer(examples['sentence1'], examples['sentence2'], truncation=True, padding='max_length')\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "validation_dataset = dataset['validation']\n",
    "\n",
    "encoded_training_dataset = train_dataset.map(tokenize_dataset, batched=True)\n",
    "encoded_validation_dataset = validation_dataset.map(tokenize_dataset, batched=True)\n",
    "encoded_test_dataset = test_dataset.map(tokenize_dataset, batched=True)\n",
    "\n",
    "encoded_training_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "encoded_validation_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "encoded_test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Map: 100%|██████████| 3668/3668 [00:03<00:00, 966.31 examples/s] \n",
    "# Map: 100%|██████████| 408/408 [00:00<00:00, 1003.11 examples/s]\n",
    "# Map: 100%|██████████| 1725/1725 [00:01<00:00, 1021.17 examples/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"len(training): {len(encoded_training_dataset)}\")\n",
    "print(f\"len(validation): {len(encoded_validation_dataset)}\")\n",
    "print(f\"len(test): {len(encoded_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure LoRA\n",
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\"  # exclude bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap model with PEFT config\n",
    "from peft import get_peft_model\n",
    "\n",
    "peft_wrapped_model = get_peft_model(base_model, lora_config)\n",
    "peft_wrapped_model.print_trainable_parameters()\n",
    "\n",
    "# trainable params: 294,912 || all params: 67,249,922 || trainable%: 0.4385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure evaluation metrics \n",
    "# in addition to the default `loss` metric that the `Trainer` computes\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "import evaluate\n",
    "\n",
    "evaluation_module = evaluate.load(HF_DATASET_COLLECTION, HF_DATASET_CONFIG_NAME)\n",
    "\n",
    "def evaluate_model(model, data_loader, device, evaluation_module=evaluation_module):\n",
    "    \"\"\" Evaluate the model on the given data loader \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    total_eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'label'}\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "            \n",
    "            probs = softmax(logits, dim=-1)\n",
    "\n",
    "            positive_probs = probs[:, 1]\n",
    "            all_probabilities.extend(positive_probs.cpu().numpy())\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    avg_loss = total_eval_loss / len(data_loader)\n",
    "    \n",
    "    results = evaluation_module.compute(predictions=all_predictions, references=all_labels)\n",
    "    results['eval_loss'] = avg_loss\n",
    "    results['probs'] = all_probabilities\n",
    "    results['labels'] = all_labels\n",
    "    return results\n",
    "\n",
    "# Downloading builder script: 100%|██████████| 5.75k/5.75k [00:00<00:00, 19.5MB/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] clean up the GPU memory\n",
    "if TRAINING_DEVICE == 'gpu':\n",
    "    from numba import cuda\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train job config\n",
    "from transformers import AdamW\n",
    "\n",
    "def train_model(\n",
    "        model, \n",
    "        train_loader,\n",
    "        validation_loader, \n",
    "        device, \n",
    "        num_epochs=TRAINING_EPOCHS, \n",
    "        learning_rate=TRAINING_LEARNING_RATE):\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    training_stats = []\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'label'}\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()   \n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        validation_results = evaluate_model(model, validation_loader, device)\n",
    "        training_stats.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Validation Loss': validation_results['eval_loss'],\n",
    "            'Validation Accuracy': validation_results['accuracy']\n",
    "        })\n",
    "        \n",
    "        print((f\"Epoch {epoch + 1} | \"\n",
    "            f\"Training Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Validation Loss: {validation_results['eval_loss']:.4f} | \"\n",
    "            f\"Validation Accuracy: {validation_results['accuracy']:.4f}\"\n",
    "        ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader/collator to batch input in training and evaluation datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    encoded_training_dataset, \n",
    "    batch_size=TRAINING_BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    encoded_validation_dataset, \n",
    "    batch_size=TRAINING_BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    encoded_test_dataset, \n",
    "    batch_size=TRAINING_BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_model(peft_wrapped_model, train_loader, validation_loader, device)\n",
    "\n",
    "# /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
    "#   warnings.warn(\n",
    "# Epoch 1 | Training Loss: 0.6517 | Validation Loss: 0.6054 | Validation Accuracy: 0.6838\n",
    "# Epoch 2 | Training Loss: 0.5940 | Validation Loss: 0.5654 | Validation Accuracy: 0.6838\n",
    "# Epoch 3 | Training Loss: 0.5571 | Validation Loss: 0.5354 | Validation Accuracy: 0.7010\n",
    "# Epoch 4 | Training Loss: 0.5148 | Validation Loss: 0.4781 | Validation Accuracy: 0.7328\n",
    "# Epoch 5 | Training Loss: 0.4663 | Validation Loss: 0.5124 | Validation Accuracy: 0.7892\n",
    "# Epoch 6 | Training Loss: 0.4258 | Validation Loss: 0.4324 | Validation Accuracy: 0.8186\n",
    "# Epoch 7 | Training Loss: 0.3962 | Validation Loss: 0.3761 | Validation Accuracy: 0.8211\n",
    "# Epoch 8 | Training Loss: 0.3706 | Validation Loss: 0.3743 | Validation Accuracy: 0.8333\n",
    "# Epoch 9 | Training Loss: 0.3612 | Validation Loss: 0.3577 | Validation Accuracy: 0.8333\n",
    "# Epoch 10 | Training Loss: 0.3445 | Validation Loss: 0.3618 | Validation Accuracy: 0.8407\n",
    "# Epoch 11 | Training Loss: 0.3223 | Validation Loss: 0.3639 | Validation Accuracy: 0.8382\n",
    "# Epoch 12 | Training Loss: 0.3097 | Validation Loss: 0.3468 | Validation Accuracy: 0.8431\n",
    "# Epoch 13 | Training Loss: 0.3045 | Validation Loss: 0.3538 | Validation Accuracy: 0.8407\n",
    "# Epoch 14 | Training Loss: 0.2839 | Validation Loss: 0.3681 | Validation Accuracy: 0.8358\n",
    "# Epoch 15 | Training Loss: 0.2716 | Validation Loss: 0.3757 | Validation Accuracy: 0.8480\n",
    "# Epoch 16 | Training Loss: 0.2630 | Validation Loss: 0.3404 | Validation Accuracy: 0.8554\n",
    "# Epoch 17 | Training Loss: 0.2538 | Validation Loss: 0.3730 | Validation Accuracy: 0.8407\n",
    "# Epoch 18 | Training Loss: 0.2367 | Validation Loss: 0.3658 | Validation Accuracy: 0.8529\n",
    "# Epoch 19 | Training Loss: 0.2245 | Validation Loss: 0.3713 | Validation Accuracy: 0.8578\n",
    "# Epoch 20 | Training Loss: 0.2191 | Validation Loss: 0.3800 | Validation Accuracy: 0.8480\n",
    "# Epoch 21 | Training Loss: 0.2095 | Validation Loss: 0.4098 | Validation Accuracy: 0.8480\n",
    "# Epoch 22 | Training Loss: 0.1957 | Validation Loss: 0.4107 | Validation Accuracy: 0.8529\n",
    "# Epoch 23 | Training Loss: 0.1860 | Validation Loss: 0.4176 | Validation Accuracy: 0.8554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the base model\n",
    "base_results = evaluate_model(base_model, test_loader, device)\n",
    "filtered_base_results = {\n",
    "    key: value for key, value in base_results.items() \n",
    "    if key not in ['probs', 'labels']\n",
    "}\n",
    "print(\"Base Model eval:\", filtered_base_results)\n",
    "\n",
    "# Base Model eval: {'accuracy': 0.36869565217391304, 'f1': 0.21710999281092738, 'eval_loss': 0.701879393171381}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval peft model\n",
    "peft_results = evaluate_model(peft_wrapped_model, test_loader, device)\n",
    "filtered_peft_results = {\n",
    "    key: value for key, value in peft_results.items() \n",
    "    if key not in ['probs', 'labels']\n",
    "}\n",
    "print(\"Fine-Tuned Model eval:\", filtered_peft_results)\n",
    "\n",
    "# Fine-Tuned Model eval: {'accuracy': 0.8266666666666667, 'f1': 0.873036093418259, 'eval_loss': 0.47620911665122817}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base Model eval:\", filtered_base_results)\n",
    "print(\"Fine-Tuned Model eval:\", filtered_peft_results)\n",
    "\n",
    "# Base Model eval: {'accuracy': 0.36869565217391304, 'f1': 0.21710999281092738, 'eval_loss': 0.701879393171381}\n",
    "# Fine-Tuned Model eval: {'accuracy': 0.8266666666666667, 'f1': 0.873036093418259, 'eval_loss': 0.47620911665122817}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import os\n",
    "\n",
    "os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n",
    "peft_wrapped_model.save_pretrained(OUTPUT_DIRECTORY)\n",
    "tokenizer.save_pretrained(OUTPUT_DIRECTORY)\n",
    "\n",
    "# ('./../data/ft_model/tokenizer_config.json',\n",
    "#  './../data/ft_model/special_tokens_map.json',\n",
    "#  './../data/ft_model/vocab.txt',\n",
    "#  './../data/ft_model/added_tokens.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save on Huggingface\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "peft_wrapped_model.push_to_hub(HUGGINGFACE_REPO_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
