{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r ./../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref. https://github.com/LC-John/Yahoo-Answers-Topic-Classification-Dataset/tree/master\n",
    "HF_DATASETS_NAME = \"community-datasets/yahoo_answers_topics\"\n",
    "CLASSES = [\n",
    "    \"Society & Culture\",\n",
    "    \"Science & Mathematics\",\n",
    "    \"Health\",\n",
    "    \"Education & Reference\",\n",
    "    \"Computers & Internet\",\n",
    "    \"Sports\",\n",
    "    \"Business & Finance\",\n",
    "    \"Entertainment & Music\",\n",
    "    \"Family & Relationships\",\n",
    "    \"Politics & Government\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pathlib\n",
    "\n",
    "CORRELATION_ID = uuid.uuid4().hex[:4].upper()\n",
    "OUTPUT_DIR = f\"./../data/{CORRELATION_ID}-{HF_DATASETS_NAME.split('/')[-1]}\"\n",
    "\n",
    "pathlib.Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"HF datasets name: {HF_DATASETS_NAME}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Correlation ID: {CORRELATION_ID}\")\n",
    "\n",
    "# HF datasets name: community-datasets/yahoo_answers_topics\n",
    "# Output directory: ./../data/C6DF-yahoo_answers_topics\n",
    "# Correlation ID: ABCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets: train, validation, test\n",
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(HF_DATASETS_NAME)  # doctest: +IGNORE_RESULT\n",
    "\n",
    "print(f\"datasets: {[k for k in datasets]}\")\n",
    "\n",
    "# datasets: ['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train = datasets['train']\n",
    "test_validtest = datasets['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "# Combine the splits into a DatasetDict\n",
    "split_datasets = DatasetDict({\n",
    "    'train': train,\n",
    "    'validation': test_validtest['train'],\n",
    "    'test': test_validtest['test']\n",
    "})\n",
    "\n",
    "print(split_datasets)\n",
    "\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['id', 'topic', 'question_title', 'question_content', 'best_answer'],\n",
    "#         num_rows: 1400000\n",
    "#     })\n",
    "#     validation: Dataset({\n",
    "#         features: ['id', 'topic', 'question_title', 'question_content', 'best_answer'],\n",
    "#         num_rows: 30000\n",
    "#     })\n",
    "#     test: Dataset({\n",
    "#         features: ['id', 'topic', 'question_title', 'question_content', 'best_answer'],\n",
    "#         num_rows: 30000\n",
    "#     })\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in each split of the dataset\n",
    "import copy\n",
    "import json\n",
    "\n",
    "qa_template = {\"prompt\": \"{prompt}\", \"completion\": \"{completion}\"}\n",
    "max_records = 2000\n",
    "\n",
    "qa_dataset = {}\n",
    "for split in split_datasets:\n",
    "    print(f\"Processing split: {split}\")\n",
    "    records = []\n",
    "    for i in range(min(len(split_datasets[split]), max_records)):\n",
    "        # print(f\"Processing record: {i}\")\n",
    "        compiled_qa = copy.deepcopy(qa_template)\n",
    "        prompt = ' '.join([\n",
    "            split_datasets[split][i][\"question_title\"],\n",
    "            split_datasets[split][i][\"question_content\"],\n",
    "            split_datasets[split][i][\"best_answer\"]\n",
    "        ])\n",
    "        compiled_qa['prompt'] = prompt\n",
    "        compiled_qa['completion'] = CLASSES[split_datasets[split][i][\"topic\"]]\n",
    "        records.append(compiled_qa)\n",
    "    qa_dataset[split] = records\n",
    "\n",
    "print(\"=\" * 16, \"\\n\", \"qa_dataset:\")\n",
    "print(json.dumps(qa_dataset['train'][:2],indent=2))\n",
    "\n",
    "# #Processing split: train\n",
    "# Processing split: validation\n",
    "# Processing split: test\n",
    "# ================ \n",
    "#  qa_dataset:\n",
    "# {\n",
    "#   \"train\": [\n",
    "#     {\n",
    "#       \"prompt\": \"why doesn't an optical mouse work on a glass table? or even on some surfaces? Optical mice use an LED and a camera to rapidly capture images of the surface beneath the mouse.  The infomation from the camera is analyzed by a DSP (Digital Signal Processor) and used to detect imperfections in the underlying surface and determine motion. Some materials, such as glass, mirrors or other very shiny, uniform surfaces interfere with the ability of the DSP to accurately analyze the surface beneath the mouse.  \\\\nSince glass is transparent and very uniform, the mouse is unable to pick up enough imperfections in the underlying surface to determine motion.  Mirrored surfaces are also a problem, since they constantly reflect back the same image, causing the DSP not to recognize motion properly. When the system is unable to see surface changes associated with movement, the mouse will not work properly.\",\n",
    "#       \"completion\": \"Computers & Internet\"\n",
    "#     },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the output file paths\n",
    "output_files = {\n",
    "    'train': f\"{OUTPUT_DIR}/{CORRELATION_ID}-train.jsonl\",\n",
    "    'validation': f\"{OUTPUT_DIR}/{CORRELATION_ID}-validation.jsonl\",\n",
    "    'test': f\"{OUTPUT_DIR}/{CORRELATION_ID}-test.jsonl\"\n",
    "}\n",
    "\n",
    "# Write each split to its respective file in JSONL format\n",
    "for split, records in qa_dataset.items():\n",
    "    with open(output_files[split], 'w') as f:\n",
    "        for record in records:\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "\n",
    "print(f\"Data exported to {OUTPUT_DIR} in JSONL format.\")\n",
    "\n",
    "# Data exported to ./../data/ABCD-yahoo_answers_topics in JSONL format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
