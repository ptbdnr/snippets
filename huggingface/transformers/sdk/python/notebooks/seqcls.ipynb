{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input constants\n",
    "import os\n",
    "import dotenv\n",
    "import torch\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HF_DATASETS_NAME = \"google-research-datasets/go_emotions\"\n",
    "HF_PRETRAINED_MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # when debugging use 'cpu' for better error messages \n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "OUTPUT_DIR = os.path.join('trained', HF_PRETRAINED_MODEL_NAME)\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"HF datasets name: {HF_DATASETS_NAME}\")\n",
    "print(f\"HF pretrained model name: {HF_PRETRAINED_MODEL_NAME}\")\n",
    "\n",
    "print(f\"Using {DEVICE} device\")\n",
    "\n",
    "print('=' * 5, 'TRAINING', '=' * 5)\n",
    "print(f\"epochs: {EPOCHS}\")\n",
    "print(f\"batch_size: {BATCH_SIZE}\")\n",
    "print(f\"learning rate (lr): {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Downloading and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets: train, validation, test\n",
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(HF_DATASETS_NAME)  # doctest: +IGNORE_RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(f\"datasets: {[k for k in datasets]}\")\n",
    "labelIds = []\n",
    "for dataset_key in datasets:\n",
    "    print(f\"len({dataset_key}): {len(datasets[dataset_key])}\")\n",
    "    [labelIds.append(l) for ls in datasets[dataset_key]['labels'] for l in ls]\n",
    "labelIds = list(set(labelIds))\n",
    "labelNames = datasets['train'].features['labels'].feature.names\n",
    "assert len(labelIds) == len(labelNames)\n",
    "labelIds.sort()\n",
    "print(f\"train dataset: {datasets['train']}\")\n",
    "print(f\"train dataset features: {datasets['train'].features}\")\n",
    "print(f\"labelIds {len(labelIds)} unique, min {min(labelIds)}, max {max(labelIds)}, first 10: {labelIds[:10]}\")\n",
    "print(f\"labelNames ({len(labelNames)} unique), first 10: {labelNames[:10]}\")\n",
    "for i in range(3):\n",
    "    print(f\"Example ({i}): {json.dumps(datasets['train'][i], indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate data\n",
    "for key, dataset in datasets.items():\n",
    "    for idx, record in enumerate(dataset):\n",
    "        assert len(record['text']) > 0, f\"{key}:{idx} - Expected text, received '{record['text']}'\"\n",
    "        assert len(record['labels']) > 0, f\"{key}:{idx} - Expected labels, received '{record['labels']}'\"\n",
    "        for label in record['labels']:\n",
    "            assert isinstance(label, int), f\"{key}:{idx} - Expected int label, received '{label}'\"\n",
    "            assert 0 <= label < len(labelIds), f\"{key}:{idx} - Expected 0<=label<len(labelIds), received '{label}'\"\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pipelines\n",
    "from transformers import pipeline\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=HF_PRETRAINED_MODEL_NAME, device=DEVICE)\n",
    "sentiment_task(\"Covid cases are increasing fast!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tokenizer, config, model\n",
    "# use_fast: False for Python-based algo when encoding is non-trivial (default), True for Rust-base algo with trivial encoding\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_PRETRAINED_MODEL_NAME, use_fast=False, device=DEVICE)\n",
    "base_config = AutoConfig.from_pretrained(HF_PRETRAINED_MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=HF_PRETRAINED_MODEL_NAME\n",
    ")\n",
    "model.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=DEVICE)\n",
    "classifier(inputs=\"This is super cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inference\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "from scipy.special import softmax\n",
    "\n",
    "input_text = datasets['train'][0]['text']\n",
    "print(f\"==INPUT TEXT==:\\n{input_text}\")\n",
    "expected_labels = datasets['train'][0]['labels']\n",
    "print(f\"==EXPECTED==:\\n{[f'{labelNames[l]} ({l})' for l in expected_labels]}\")\n",
    "encoded_inputs = tokenizer(input_text, return_tensors='pt').to(device=DEVICE)\n",
    "outputs = model(**encoded_inputs)\n",
    "logits = outputs[0][0].detach()\n",
    "scores = softmax(logits.to('cpu'))\n",
    "config = AutoConfig.from_pretrained(HF_PRETRAINED_MODEL_NAME)\n",
    "print(f\"==OUTPUT==:\\n{[{config.id2label[i]: scores[i]} for i in range(len(logits))]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model with target number of labels\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=HF_PRETRAINED_MODEL_NAME,\n",
    "    num_labels=max(labelIds),\n",
    "    ignore_mismatched_sizes=True  # because original model's num_labels < expected model's num_labels \n",
    ")\n",
    "model.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of (optionally, trainable or non-embeddings) parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the dataset\n",
    "# Hugging Face Transformers models expect tokenized input, rather than a string text.\n",
    "def tokenize_dataset(dataset):\n",
    "    # encode text to input_ids and attention_mask\n",
    "    encoded_text = tokenizer(\n",
    "        text=dataset[\"text\"],\n",
    "        padding='max_length',  # add special padding token to create uniform-length inputs of 'max_length'\n",
    "        truncation=True,  # truncate to 'max_length'\n",
    "        max_length=base_config.max_position_embeddings,\n",
    "        return_tensors='pt')\n",
    "    dataset['input_ids'] = encoded_text.input_ids\n",
    "    dataset['attention_mask'] = encoded_text.attention_mask\n",
    "    # encode labels from List[List[int]] to List[int]\n",
    "    first_labels = []\n",
    "    for labels in dataset['labels']:\n",
    "        first_label = labels[0]\n",
    "        first_labels.append(first_label)\n",
    "    # print(f\"first labels {len(set(first_labels))} unique, min {min(first_labels)} max {max(first_labels)}\")\n",
    "    dataset['labels'] = first_labels\n",
    "    return dataset\n",
    "\n",
    "encoded_datasets = datasets.map(\n",
    "    tokenize_dataset, \n",
    "    batched=True,\n",
    "    remove_columns=['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(f\"datasets: {[k for k in encoded_datasets]}\")\n",
    "for dataset_key in encoded_datasets:\n",
    "    print(f\"len({dataset_key}): {len(encoded_datasets[dataset_key])}\")\n",
    "print(f\"train dataset: {encoded_datasets['train']}\")\n",
    "print(f\"train dataset features: {encoded_datasets['train'].features}\")\n",
    "for i in range(3):\n",
    "    print(f\"Example ({i}): {json.dumps(encoded_datasets['train'][i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader/collator to batch input in training and evaluation datasets\n",
    "# DataCollatorWithPadding pads dynamically your text to the length of the longest element in its batch, \n",
    "# so they are a uniform length\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure evaluation metrics in addition to the default `loss` metric that the `Trainer` computes\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the GPU memory\n",
    "if DEVICE == 'gpu':\n",
    "    from numba import cuda\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] TROUBLESHOOTING\n",
    "# huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "# To disable this warning, you can either:\n",
    "#\t- Avoid using `tokenizers` before the fork if possible\n",
    "#\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "# See: https://github.com/huggingface/transformers/issues/5486\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # default: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train job config\n",
    "# Hugging Face training configuration tools can be used to configure a <T>Trainer.\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    \n",
    "    #do_train=True,\n",
    "    #do_eval=True,\n",
    "\n",
    "    num_train_epochs=1,    \n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    \n",
    "    weight_decay=0.01,\n",
    "    #gradient_accumulation_steps=2,  # default 1\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"f1\"\n",
    "    \n",
    "    fp16=True,  # lower precision\n",
    "    # use_ipex=True if DEVICE == 'cpu' else False,  # use Intel extension for PyTorch\n",
    "    use_cpu=True if DEVICE == 'cpu' else False  # False will use CUDA or MPS if available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] TROUBLESHOOTHING\n",
    "# IF\n",
    "# RuntimeError: CUDA error: device-side assert triggered\n",
    "# CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
    "# For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
    "# Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "# IF still errors out try DEVICE = 'cpu' to see error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The <T>Trainer classes require the user to provide: 1) Metrics 2) A base model 3) A training configuration\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using GPU, then during training job monitor compute instance in terminal with cli command `nvidia-smi`\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
